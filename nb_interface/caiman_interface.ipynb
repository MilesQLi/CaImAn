{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "nbpresent": {
     "id": "790f1d6b-6a21-4009-85ef-31964fcfa7b1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonbrown/anaconda/envs/caiman2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from caiman_interface import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 2,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# <em>Ca</em><font color=\"grey\">lcium</font> <em>Im</em><font color=\"grey\">aging</font> <em>An</em><font color=\"grey\">alysis</font>\n",
    "### Jupyter Notebook Interface (alpha version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "##### Manage Context\n",
    "The context is the data that is saved during each step of the analysis. You can save all of your work as a `context` file with the extension `.pkl`. For example, if you finish the CNMF-E analysis step, you can save your context, and then re-load it later to view the results interactively here. Please note the context files are large, so only save if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f23922dbbbd4152bea8c00a0187c5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='Idle', description='<b>Status:</b>', layout=Layout(width='90%')), Tab(children=(VBoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "display(app_ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "##### Motion Correction Parameters:\n",
    "- Grouped?  If your folder contains movies from the _same_ experiment, i.e. if your recording software produces multiple segments of a single recording, then select \"Group\" so these will be combined in the analysis to a single movie. If your folder contains movies from different recordings, select \"Independent\" so they will be run separately.\n",
    "- Downsample factors are percentages from 0 to 1. If you enter 0.5 for height and width, then the movie resolution will be halved. E.g. if you have a 500px by 500px movie, it will be downsampled to 250px by 250px. You can also downsample in the time domain, i.e. if your movie has 1000 frames, entering 0.5 will downsample the frames to 500 frames. This should only be done if you're recording at a high frame rate.\n",
    "- \"High Pass\" setting should be left at default value.\n",
    "- Motion Correction has two modes: rigid and non-rigid. Rigid is much faster. Non-rigid should be used when the movie has non-rigid (elastic) motions/deformations. This can sometimes happen given with _in vivo_ brain recordings since the brain is an elastic organ.\n",
    "- MC Results: This section is under development. Currently you can only view a side-by-side of the original movie with the motion corrected movie. The movies will pop-up in a separate window. Press the __Q__ key on your keyboard to close the movie window.\n",
    "\n",
    "##### CNMF-E Parameters:\n",
    "- Patches? CNMF-E can run in two modes: patches or single field of view (FOV). Patches mode will break up each frame into multiple pieces and process them independently. On computers with multiple processors, this can be much faster. However, patches mode can produce unwanted reconstruction artifacts when the pieces are poorly re-assembled.\n",
    "- You can downsample in the CNMF-E stage, spatially (height and width) and temporally (frames/time). However, if you already downsampled during motion correction, you probably should not downsample again.\n",
    "- __K__: K is the estimated number of neurons in your field of view. This parameter helps the algorithm detect the correct number of neurons. It does not need to be highly accurate; an over-estimate is better.\n",
    "- __gSig__: This is the estimated half-width (radius) of each neuron in the movie, in pixel values. The default value will work in most cases.\n",
    "- __gSiz__: This is related to gSig and typically the default value will work fine.\n",
    "\n",
    "##### CNMF-E Results Viewer\n",
    "- This interface allows you to look at a \"Z-projection\" (i.e. flattened video) of the data to see how well the CNMF-E algorithm did at detecting neurons and avoiding noise. In the top left is a the Z-projected image with red dots denoting the neurons it detected. \n",
    "- In general, CNMF-E _will_ think some noise is a neuron. In that case, you need to look through the traces and at the image panels to see which cells are noise and press the `Delete ROI` button. This will not modify the `context`. This just excludes those ROIs if you download the data as a file.\n",
    "- Check the `Use dF/F` checkbox if you want to convert the signals to delta fluorescence / fluorescence. This is a necessary step if you want to be able to compare the signals between animals and recording sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#clean_up(stop_server=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:caiman2]",
   "language": "python",
   "name": "conda-env-caiman2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
